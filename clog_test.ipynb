{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "import time\n",
    "import dateutil.parser\n",
    "import datetime\n",
    "import gc\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "import pprint\n",
    "\n",
    "\n",
    "sys.path.insert(0, '../cli_test\\API-V2-Python-examples')\n",
    "import TAHMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TAHMODATA:\n",
    "    WEATHER_DATA: https://datahub.tahmo.org/services/measurements/v2/stations    \n",
    "    WEATHER_DATA_RAW: measurements/raw   \n",
    "    STATION_INFO: https://datahub.tahmo.org/services/assets/v2/stations\n",
    "    DATA_COMPLETE: https://datahub.tahmo.org/custom/sensordx/latestmeasurements\n",
    "    STATION_STATUS: https://datahub.tahmo.org/custom/stations/status   # this is new\n",
    "    LAST_MEASUREMENT_OFFSET: 55\n",
    "    USE_ONLY_ONE_MEASUREMENT: false\n",
    "    ALWAYS_RETURN_TRUE: true\n",
    "    STATIONS VARIABLES: https://datahub.tahmo.org/services/assets/v2/variables\n",
    "'''\n",
    "'''\n",
    "TAHMOQC:\n",
    "    BASE_URL: https://tahmorqctest.eu-de.mybluemix.net  # test https://tahmorqctest.eu-de.mybluemix.net\n",
    "    SCORE_SUFFIX: /api/score\n",
    "    ALL_MODELS_SUFFIX: /api/models\n",
    "    SINGLE_MODEL_SUFFIX: /api/station   # /model is for getting by the model _id, not the station name\n",
    "    SECRET_USER_PW: \"6GUXzKi#wvDvZ\"\n",
    "    SECRET_USER_NAME: \"SensorDxKenya\"\n",
    "    SAVE_SCORE_RESULTS: true\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "API_BASE_URL = 'https://datahub.tahmo.org'\n",
    "API_MAX_PERIOD = '365D'\n",
    "apiKey = 'SensorDxKenya'\n",
    "apiSecret = '6GUXzKi#wvDvZ'\n",
    "endpoints = {'VARIABLES': 'services/assets/v2/variables', # 28 different variables\n",
    "             'STATION_INFO': 'services/assets/v2/stations',\n",
    "             'WEATHER_DATA': 'services/measurements/v2/stations', # Configured before requesting\n",
    "             'DATA_COMPLETE': 'custom/sensordx/latestmeasurements',\n",
    "             'STATION_STATUS': 'custom/stations/status'}\n",
    "# Precipitation variable\n",
    "'''\n",
    "\"created\": \"2018-10-25T14:12:08.885918Z\"\n",
    "'''\n",
    "api = TAHMO.apiWrapper()\n",
    "api.setCredentials('SensorDxKenya', '6GUXzKi#wvDvZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __handleApiError(apiRequest):\n",
    "    json =None\n",
    "    try:\n",
    "        json = apiRequest.json()\n",
    "    finally:\n",
    "        if json and 'error' in json and 'message' in json['error']:\n",
    "            print(json)\n",
    "            raise Exception(json['error']['message'])\n",
    "        else:\n",
    "            raise Exception(f'API request failed with status code {apiRequest.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __request(endpoint, params):\n",
    "    print(f'API request: {endpoint}')\n",
    "    apiRequest = requests.get(f'{API_BASE_URL}/{endpoint}',\n",
    "                                params=params,\n",
    "                                auth=requests.auth.HTTPBasicAuth(\n",
    "                                apiKey,\n",
    "                                apiSecret\n",
    "                            )\n",
    "    )\n",
    "    if apiRequest.status_code == 200:\n",
    "        return apiRequest.json()\n",
    "    else:\n",
    "        return __handleApiError(apiRequest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVariables():\n",
    "    # endpoints['VARIABLES']\n",
    "    response = __request(endpoints['VARIABLES'], {})\n",
    "    variables = {}\n",
    "    if 'data' in response and isinstance(response['data'], list):\n",
    "        for element in response['data']:\n",
    "            variables[element['variable']['shortcode']] = element['variable']\n",
    "    return variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStations():\n",
    "    response = __request(endpoints['STATION_INFO'], {'sort':'code'})\n",
    "    stations = {}\n",
    "    if 'data' in response and isinstance(response['data'], list):\n",
    "        for element in response['data']:\n",
    "            stations[element['code']] = element\n",
    "    return stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __splitDateRange(inputStartDate, inputEndDate):\n",
    "    try:\n",
    "        startDate = dateutil.parser.parse(inputStartDate)\n",
    "        endDate = dateutil.parser.parse(inputEndDate)\n",
    "        \n",
    "    except ValueError:\n",
    "        raise ValueError('Invalid data parameters')\n",
    "    \n",
    "    # Split into intervals of 365 days\n",
    "    dates = pd.date_range(start=startDate.strftime('%Y%m%d'), end=endDate.strftime('%Y%m%d'), freq=API_MAX_PERIOD)\n",
    "    df = pd.DataFrame([[i, x] for i, x in\n",
    "                           zip(dates, dates.shift(1) - datetime.timedelta(seconds=1))],\n",
    "                          columns=['start', 'end'])\n",
    "\n",
    "    # Set start and end date to their provided values.\n",
    "    df.loc[0, 'start'] = pd.Timestamp(startDate)\n",
    "    df['end'].iloc[-1] = pd.Timestamp(endDate)\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datess = __splitDateRange('2017-01-01', '2022-10-31')\n",
    "type(datess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-12-31 23:59:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-12-31 23:59:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-12-31 23:59:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-12-30 23:59:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2021-12-30 23:59:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>2022-10-31 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       start                 end\n",
       "0 2017-01-01 2017-12-31 23:59:59\n",
       "1 2018-01-01 2018-12-31 23:59:59\n",
       "2 2019-01-01 2019-12-31 23:59:59\n",
       "3 2020-01-01 2020-12-30 23:59:59\n",
       "4 2020-12-31 2021-12-30 23:59:59\n",
       "5 2021-12-31 2022-10-31 00:00:00"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeasurements(station, startDate=None, endDate=None, variables=None, dataset='controlled'):\n",
    "    endpoints = f'services/measurements/v2/stations/{station}/measurements/{dataset}'\n",
    "    datesplit = __splitDateRange(startDate, endDate)\n",
    "    series = []\n",
    "    seriesHolder = {}\n",
    "\n",
    "    # retrieving the rows for the dates \n",
    "    for index, row in datesplit.iterrows():\n",
    "        params = {\n",
    "            'start': row['start'].strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "            'end'  : row['end'].strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        }\n",
    "        if variables and isinstance(variables, list) and len(variables) == 1:\n",
    "            params['variable'] = variables[0]\n",
    "        response = __request(endpoints, params)\n",
    "\n",
    "        # checking for values within the json\n",
    "        if 'results' in response and len(response['results']) >= 1 and 'series' in response[\n",
    "            'results'][0] and len(response['results'][0]['series']) >= 1 and 'values' in response['results'\n",
    "            ][0]['series'][0]:\n",
    "            # values stored in result key series, values\n",
    "\n",
    "            for result in response['results']:\n",
    "                if 'series' in result and len(result['series']) >= 1 and 'values' in result['series'][0]:\n",
    "                    for serie in result['series']:\n",
    "                        columns = serie['columns']\n",
    "                        observations = serie['values']\n",
    "\n",
    "                        time_index = columns.index('time')\n",
    "                        quality_index = columns.index('quality')\n",
    "                        variable_index = columns.index('variable')\n",
    "                        sensor_index = columns.index('sensor')\n",
    "                        value_index = columns.index('value')\n",
    "\n",
    "                        # Create list of unique variables within the retrieved observations.\n",
    "                        if not isinstance(variables, list) or len(variables) == 0:\n",
    "                            shortcodes = list(set(list(map(lambda x: x[variable_index], observations))))\n",
    "                        else:\n",
    "                            shortcodes = variables\n",
    "                        \n",
    "                        for shortcode in shortcodes:\n",
    "    \n",
    "                            # Create list of timeserie elements for this variable with predefined format [time, value, sensor, quality].\n",
    "                            timeserie = list(map(lambda x: [x[time_index], x[value_index] if x[quality_index] == 1 else np.nan, x[sensor_index], x[quality_index]],\n",
    "                                                    list(filter(lambda x: x[variable_index] == shortcode, observations))))\n",
    "                            \n",
    "                            if shortcode in seriesHolder:\n",
    "                                seriesHolder[shortcode] = seriesHolder[shortcode] + timeserie\n",
    "                            else:\n",
    "                                seriesHolder[shortcode] = timeserie\n",
    "                                \n",
    "                            # Clean up scope.\n",
    "                            del timeserie\n",
    "\n",
    "                        # Clean up scope.\n",
    "                        del columns\n",
    "                        del observations\n",
    "                        del shortcodes\n",
    "\n",
    "                # Clean up scope and free memory.\n",
    "            del response\n",
    "            gc.collect()\n",
    "    for shortcode in seriesHolder:\n",
    "\n",
    "        # Check if there are duplicate entries in this timeseries (multiple sensors for same variable).\n",
    "        # [time, value, sensor, quality]\n",
    "        timestamps = list(map(lambda x: x[0], seriesHolder[shortcode]))\n",
    "        \n",
    "        def element_1(x):\n",
    "            return x[1],x[3]\n",
    "        # if multiple sensors\n",
    "        if len(timestamps) > len(set(timestamps)):\n",
    "            # Split observation per sensor\n",
    "            print('Split observations for %s per sensor' % shortcode)\n",
    "            sensors = list(set(list(map(lambda x: x[2], seriesHolder[shortcode]))))\n",
    "\n",
    "            for sensor in sensors:\n",
    "                sensorSerie = list(filter(lambda x: x[2] == sensor, seriesHolder[shortcode]))\n",
    "                timestamps = list(map(lambda x: pd.Timestamp(x[0]), sensorSerie))\n",
    "                values = list(map(lambda x: x[1], sensorSerie))\n",
    "                flags = list(map(lambda x: x[3], sensorSerie))\n",
    "                # print(sensorSerie)\n",
    "                flags_vals = list(map(element_1, sensorSerie))\n",
    "\n",
    "                code = list(map(lambda x: x[0], flags_vals))\n",
    "                quality = list(map(lambda x: x[1], flags_vals))\n",
    "\n",
    "                code_series = pd.Series(code, index=pd.DatetimeIndex(timestamps))\n",
    "                quality_series = pd.Series(quality, index=pd.DatetimeIndex(timestamps))\n",
    "\n",
    "                serie = pd.Series(flags_vals, index=pd.DatetimeIndex(timestamps))\n",
    "\n",
    "                both = pd.concat(objs=[code_series, quality_series], axis=1)\n",
    "                both.columns = [f'{shortcode}_{station}_{sensor}', f'Qc_{station}']\n",
    "                \n",
    "                # series.append(serie.to_frame('%s_%s' % (shortcode, sensor)))\n",
    "                series.append(both)\n",
    "\n",
    "                # Clean up scope.\n",
    "                del sensorSerie\n",
    "                del timestamps\n",
    "                del values\n",
    "                del serie\n",
    "        else:\n",
    "            values = list(map(element_1, seriesHolder[shortcode]))\n",
    "            serie = pd.Series(values, index=pd.DatetimeIndex(timestamps))\n",
    "\n",
    "            code = list(map(lambda x: x[0], values))\n",
    "            quality = list(map(lambda x: x[1], values))\n",
    "\n",
    "            code_series = pd.Series(code, index=pd.DatetimeIndex(timestamps))\n",
    "            quality_series = pd.Series(quality, index=pd.DatetimeIndex(timestamps))\n",
    "\n",
    "            both = pd.concat(objs=[code_series, quality_series], axis=1)\n",
    "            both.columns = [f'{shortcode}_{station}_{list(set(list(map(lambda x: x[2], seriesHolder[shortcode]))))[0]}', f'Qc_{station}']\n",
    "            \n",
    "            # series.append(serie.to_frame('%s_%s' % (shortcode, sensor)))\n",
    "            series.append(both)\n",
    "\n",
    "            # Clean up scope.\n",
    "            del values\n",
    "            del serie\n",
    "\n",
    "        # Clean up memory.\n",
    "        gc.collect()\n",
    "\n",
    "    # # Clean up.\n",
    "    del seriesHolder\n",
    "    gc.collect()\n",
    "\n",
    "    # Merge all series together.\n",
    "    if len(series) > 0:\n",
    "        df = pd.concat(series, axis=1, sort=True)\n",
    "    else:\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "    # Clean up memory.\n",
    "    del series\n",
    "    gc.collect()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_list = [i for i in list(getStations()) if i[1] != 'H']\n",
    "stations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "676"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = []\n",
    "df_stats = []\n",
    "count = 0\n",
    "for station in stations_list:\n",
    "    count += 1\n",
    "    \n",
    "    print(station)\n",
    "    # if station not in problem:\n",
    "    try:\n",
    "        data = getMeasurements(station, '2017-01-01', '2022-10-31', variables=['pr'], dataset='controlled')\n",
    "        # df_stats.append(data)\n",
    "        df_stats.append(data)\n",
    "        df = pd.concat(df_stats, axis=1)\n",
    "        \n",
    "        # print(df)\n",
    "    except UnboundLocalError:\n",
    "        problems.append(station)\n",
    "        print(problems)\n",
    "    df = pd.concat(df_stats, axis=1)\n",
    "    df.to_csv('stati0n677.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd76de9a08fdb969f68b31a57b79dea66bb354afca1625b2c71659650b4a59c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
